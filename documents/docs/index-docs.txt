Index:

implementing indexes:

CREATE TABLE account (
  account_id SERIAL PRIMARY KEY,
  name TEXT NOT NULL,
  dob DATE  // date of birth
);

CREATE TABLE thread(
  thread_id SERIAL PRIMARY KEY,
  account_id INTEGER NOT NULL REFERENCES account (account_id),
  title TEXT NOT NULL
);

// post table is going to contain most of our data.
CREATE TABLE post(
  post_id SERIAL PRIMARY KYE
  thread_id INTEGER NOT NULL REFERENCES thread (thread_id),
  account_id INTEGER NOT NULL REFERENCES account (account_id),
  created TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
  comment TEXT NOT NULL
);

CREATE TABLE words(word TEXT);

now we generate 100 random users, 1000 threads, 100,000 random posts,
with 20 random words in each.

this basically costs the space

table_name  | total     | index     | table
------------------------------------------------
thread      | 160 kb    | 40 kb     | 112 kb
account     | 32 kb     | 16 kb     | 8192 bytes
post        | 27 mb     | 2208 kb   | 24 mb
words       | 4168 kb   | 0 bytes   | 4160 kb

we didn't declare any indexes yet, but there's one there already, because we declared the primary_key unique 
and postgres is actually going to create an index so it can track of that and make sure that it is unique

now our tables include a sequence of pages. for example we have 1 page for account, 5 for threads and many pages for post (24)
in any individual pages, we have a 'Page Header' which let us know, is it live? what's going on? how old is it?
what transactions its involved in? and so on...
we also have another section named 'ItemID Data' which is a list of pointers into the page of where every tuple actually starts.
so every tuple in that table is referenced by page number and ItemID.
this together allows you to uniquely reference a record in your database.

// first query

SELECT * FROM post
WHERE account_id = 1;

if we execute it by saying 

EXPLAIN ANALAYZE
SELECT * FROM post
WHERE account_id = 1;

it gives us the compile information.
for example it says it Filtered (account_id = 1) and removed 99441 rows by filtering them. because they where not (account_id=1)
so it's a waste of time. and it takes 32.102 ms.

whenever we use indexing (for non_clustered indexing) it uses B-Tree search, which is a self-balancing search tree.
it searches data based on being greater or less than the desired data, at the end, it reaches the leaf nodes which
any leaf node has a link to the next leaf, so if we want 2 numbers or records, we don't have to climb back up the tree 
and back down the specific leaf.

so we add an index. (create index on table post for account_id):

CREATE INDEX [index name] ON [table name] ( [column name] )
---
CREATE INDEX ON post (account_id);

and now:


table_name  | total     | index     | table
------------------------------------------------
thread      | 160 kb    | 40 kb     | 112 kb
account     | 32 kb     | 16 kb     | 8192 bytes
post        | 29 mb     | 4416 kb   | 24 mb
words       | 4168 kb   | 0 bytes   | 4160 kb

the index costs 4416kb for post. that's a doubled in size.
but in the comparison of post size which is 24MB, Index size is only 2MB

now if we say:

EXPLAIN ANALAYZE
SELECT * FROM post
WHERE account_id = 1;

now we have a Bitmap index scan on that index which is implemented on post.
and the execution time is now 6.767ms which was 32ms before.

// the second query:
SELECT COUNT(*) FROM post 
WHERE account_id = 1;     // it also has less execution time.

// third query:
CREATE INDEX ON post(thread_id)

SELECT * FROM post
WHERE thread_id = 1 AND visible = TRUE;

// forth query:
SELECT COUNT(*)
FROM post
WHERE thread_id = 1 AND visible = TRUE AND account_id = 1;

so here, postgres combines the indexes it knows about.
it will be executed really fast

but we can create index on multiple fields.

CREATE INDEX ON post (thread_id, visible);

or we can do it better:

CREATE INDEX ON post (thread_id, account_id, visible);

the problem here, is that all these 3 indexes that we added for 1 table, 
takes storage of disk and ram.
and it takes more time to insert or update a record. so any time we want to 
write a record, we should write 3 or 4 records for indexes as well.

solution: Partial indexes:
why have index entries for records we don't want?

CREATE INDEX ON post (thread_id, account_id)
WHERE visible = TRUE;

so we leave 'visible' out of the index, and say we only put things in the index 
where visible is true

we can still use this index for queries which doesn't need to fill all fields of the index like third query:

SELECT * FROM post
WHERE thread_id = 1 AND visible = TRUE;

but how can we use this index when not referring to all the fields in the index?
because the index is the sorted of the list of keys to values and in both index and query we have thread_id

// fifth query:
SELECT * FROM post
WHERE thread_id = 1 AND visible = TRUE created > NOW() - '1 month'::interval
ORDER BY created;

with the index we have right now, it executes really fast, but we can do it better and 
have a specific index for this query.

CREATE INDEX ON post (thread_id, created)
WHERE visible = TRUE;
------------------------------------------------------------
so we can make a table clustered by:

CLUSTER [VERBOSE] table_name [ USING index_name ]
CLUSTER [VERBOSE]

CLUSTER instructs PostgreSQL to cluster the table specified by table_name based on the index specified by index_name.
The index must already have been defined on table_name.

EX)
Cluster the table employees on the basis of its index employees_ind:
CLUSTER employees USING employees_ind;

Cluster the employees table using the same index that was used before:
CLUSTER employees;

Cluster all tables in the database that have previously been clustered:
CLUSTER;

here we clustered the table with it's primary_key.
When a table is clustered, it is physically reordered based on the index information. 
Clustering is a one-time operation: when the table is subsequently updated, the changes are not clustered. 
That is, no attempt is made to store new or updated rows according to their index order.

EX)
Creating a table
CREATE TABLE IF NOT EXISTS profile(
    uid serial NOT NULL UNIQUE PRIMARY KEY,
    username varchar(30) NOT NULL UNIQUE,
    phone varchar(11) NOT NULL UNIQUE,
    age smallint CHECK(age>12),
    address text NULL
);

3 index will be created automatically. All these indexes are non clustered
"profile_pkey" PRIMARY KEY, btree (uid)
"profile_phone_key" UNIQUE CONSTRAINT, btree (phone)
"profile_username_key" UNIQUE CONSTRAINT, btree (username)

Create our own index with uid and username
CREATE INDEX profile_index ON profile(uid, username);

This is actually a non cluster index. Now make it to the cluster index

Making a non cluster index to a cluster one
ALTER TABLE profile CLUSTER ON profile_index;

*** it's not common to use both clustered and non_clustered indexes on same table.
    we should choose either one of them.

A lot of people like to put the clustered index on their table’s primary key (PK). 
This is usually fine because a lot of the time our primary key is likely to be our 
most used field for joins, where statements, etc…

in non_clustered:
If those additional lookups are hurting performance, what you can do is INCLUDE 
your nonindexed columns in your nonclustered index. What this basically does is 
in addition to storing the sorted values of your indexed column(s), the index 
will also store whatever additional values you want to include as part of the 
index itself. Once again, you’ll probably get better performance because SQL 
won’t have to go to somewhere else on disk to find the data it needs, but you 
lose storage space because you are creating duplicates of that data as part of 
your index.

Different scenarios
---
You have OLTP data that’s used only for transactional reads and writing new rows. 
You know the primary key is an identity integer column. What type of index would 
you create for the primary key?

Clustered index — Your queries are probably always going to be looking up by PK 
to return data. If you store the data in the table ordered by that PK, SQL will 
be able to do this very quickly. 

---

You have a query that wants to return most or all of the columns from a table. 
What type of index would make this the most efficient?

Clustered index — Since all of the column values are stored in the same location 
as your indexed fields, SQL won’t have to go do any additional lookups to get all 
of the data you are requesting from it. If you created a nonclustered index you 
would have to INCLUDE all nonindexed columns, which would take up lots of space 
since you are essentially duplicating your entire table’s data.

---

You have a table that is constantly having values updated. These updated values are 
used as in your JOINs and WHERE clauses. What type of index would you add?

Nonclustered index — If our values are constantly changing, SQL only has to update 
the index and pointers while putting the actual data wherever it has available space 
on disk. Compare this to a clustered index where it has to put the inserted/updated 
data in the correct order, meaning potentially lots of operations to shift the data 
around if available free space doesn’t exist at that location.

*** so for huge table with lots of columns we should use the non_clustered indexing 
    because if we use clustered indexing, we cost a lot for updating a data of a column.

---

You have a table that already has a clustered index, but it doesn’t cover columns in 
JOINs and WHERE clauses. What do you do?

Nonclustered index — since the clustered index already exists, your only option is to 
add a nonclustered index. Depending on the queries hitting this table however, you may 
want to consider changing your clustered index to a nonclustered index if you think 
your JOINs and WHERE clauses will be improved by having those fields be part of the 
clustered index. (so change it to nonclustered index)

---

You have a small staging table that you will always read all rows from and then truncate. 
You don’t care about the order. Do you add an index?

No, leave it as a heap 

---

example of our project:
---
the table:

CREATE TABLE cloth(
cloth_id serial UNIQUE PRIMARY KEY,
cloth_sub_category_id integer NOT NULL,
designer_id integer NOT NULL,
title VARCHAR (50) NOT NULL,
information text NOT NULL,
picture VARCHAR(355) [] NOT NULL,
combination_material text NOT NULL,
cleaning_order text NOT NULL,
other_wearing text,
color varchar(20) [],
share_link varchar(355) UNIQUE NOT NULL,
season VARCHAR(20),
what_kind_of_person VARCHAR (20) NOT NULL,
price real NOT NULL,
price_with_discount real,
number_of_purchase integer,
is_product BOOLEAN DEFAULT 'true' NOT NULL,
	
created_date TIMESTAMP NOT NULL default current_timestamp,
last_update TIMESTAMP,
deleted_at TIMESTAMP,	
	
	CONSTRAINT cloth_cloth_sub_category_id_fkey FOREIGN KEY (cloth_sub_category_id)
		REFERENCES cloth_sub_category (cloth_sub_category_id) MATCH SIMPLE
		ON UPDATE NO ACTION ON DELETE NO ACTION,
	
	CONSTRAINT cloth_designer_id_fkey FOREIGN KEY (designer_id)
		REFERENCES designer (designer_id) MATCH SIMPLE
		ON UPDATE NO ACTION ON DELETE NO ACTION
);
---
the index:
---
CREATE INDEX cloth_partial_index on cloth (cloth_sub_category_id,designer_id,color,season,last_update)
WHERE (deleted_at != NULL, last_update != NULL);
---
the command we can use:
---
SELECT * FROM cloth 
WHERE (deleted_at != NULL,last_update != NULL) 
ORDER BY updated_on;
